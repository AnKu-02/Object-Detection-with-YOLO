{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2aaa7f7",
   "metadata": {},
   "source": [
    "# üü¢ Real-Time Object Detection with YOLOv8 COCO and Intel RealSense D435\n",
    "\n",
    "This notebook demonstrates real-time object detection using the YOLOv8 COCO model and Intel RealSense D435 camera."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75a4516",
   "metadata": {},
   "source": [
    "## 1. Install Required Packages\n",
    "\n",
    "Run this cell to install all necessary Python packages for RealSense and YOLOv8 detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d1bbdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyrealsense2 in .\\maira7m\\venv_realsense\\lib\\site-packages (2.56.5.9235)\n",
      "Requirement already satisfied: opencv-python in .\\maira7m\\venv_realsense\\lib\\site-packages (4.13.0.90)\n",
      "Requirement already satisfied: ultralytics in .\\maira7m\\venv_realsense\\lib\\site-packages (8.4.9)\n",
      "Requirement already satisfied: numpy in .\\maira7m\\venv_realsense\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: matplotlib in .\\maira7m\\venv_realsense\\lib\\site-packages (3.9.4)\n",
      "Requirement already satisfied: pillow>=7.1.2 in .\\maira7m\\venv_realsense\\lib\\site-packages (from ultralytics) (11.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in .\\maira7m\\venv_realsense\\lib\\site-packages (from ultralytics) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.23.0 in .\\maira7m\\venv_realsense\\lib\\site-packages (from ultralytics) (2.32.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in .\\maira7m\\venv_realsense\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in .\\maira7m\\venv_realsense\\lib\\site-packages (from ultralytics) (2.8.0+cu128)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in .\\maira7m\\venv_realsense\\lib\\site-packages (from ultralytics) (0.23.0+cu128)\n",
      "Requirement already satisfied: psutil>=5.8.0 in .\\maira7m\\venv_realsense\\lib\\site-packages (from ultralytics) (7.2.2)\n",
      "Requirement already satisfied: polars>=0.20.0 in .\\maira7m\\venv_realsense\\lib\\site-packages (from ultralytics) (1.36.1)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.18 in .\\maira7m\\venv_realsense\\lib\\site-packages (from ultralytics) (2.0.18)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in .\\maira7m\\venv_realsense\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in .\\maira7m\\venv_realsense\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in .\\maira7m\\venv_realsense\\lib\\site-packages (from matplotlib) (4.60.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in .\\maira7m\\venv_realsense\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in .\\maira7m\\venv_realsense\\lib\\site-packages (from matplotlib) (26.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in .\\maira7m\\venv_realsense\\lib\\site-packages (from matplotlib) (3.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in .\\maira7m\\venv_realsense\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in .\\maira7m\\venv_realsense\\lib\\site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in .\\maira7m\\venv_realsense\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.23.0)\n",
      "Requirement already satisfied: polars-runtime-32==1.36.1 in .\\maira7m\\venv_realsense\\lib\\site-packages (from polars>=0.20.0->ultralytics) (1.36.1)\n",
      "Requirement already satisfied: six>=1.5 in .\\maira7m\\venv_realsense\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in .\\maira7m\\venv_realsense\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\maira7m\\venv_realsense\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\maira7m\\venv_realsense\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\maira7m\\venv_realsense\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2026.1.4)\n",
      "Requirement already satisfied: filelock in .\\maira7m\\venv_realsense\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in .\\maira7m\\venv_realsense\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in .\\maira7m\\venv_realsense\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx in .\\maira7m\\venv_realsense\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in .\\maira7m\\venv_realsense\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in .\\maira7m\\venv_realsense\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2025.10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in .\\maira7m\\venv_realsense\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in .\\maira7m\\venv_realsense\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (run once)\n",
    "%pip install pyrealsense2 opencv-python ultralytics numpy matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63672580",
   "metadata": {},
   "source": [
    "## 2. Import Libraries\n",
    "\n",
    "Import all necessary libraries for RealSense, YOLOv8, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a95e3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "import torch\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e985fc7c",
   "metadata": {},
   "source": [
    "## 3. Verify RealSense Camera Connection\n",
    "\n",
    "Check if the Intel RealSense D435 camera is connected and print device information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5071f627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Device 0: Intel RealSense D435\n",
      "   Serial Number: 236522071516\n",
      "   Firmware Version: 5.16.0.1\n",
      "   USB Type: 3.2\n"
     ]
    }
   ],
   "source": [
    "# Check for connected RealSense devices\n",
    "ctx = rs.context()\n",
    "devices = ctx.query_devices()\n",
    "\n",
    "if len(devices) == 0:\n",
    "    print(\"‚ùå No RealSense device detected!\")\n",
    "    print(\"   Make sure your D435 is connected via USB 3.0\")\n",
    "else:\n",
    "    for i, dev in enumerate(devices):\n",
    "        print(f\"‚úÖ Device {i}: {dev.get_info(rs.camera_info.name)}\")\n",
    "        print(f\"   Serial Number: {dev.get_info(rs.camera_info.serial_number)}\")\n",
    "        print(f\"   Firmware Version: {dev.get_info(rs.camera_info.firmware_version)}\")\n",
    "        print(f\"   USB Type: {dev.get_info(rs.camera_info.usb_type_descriptor)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bba853f",
   "metadata": {},
   "source": [
    "## 4. Initialize Camera Pipeline\n",
    "\n",
    "Configure and start the RealSense camera pipeline for color and depth streams at 640x480 resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efce2682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Camera pipeline started!\n",
      "   Color Stream: 640x480 @ 30fps\n",
      "   Depth Stream: 640x480 @ 30fps\n"
     ]
    }
   ],
   "source": [
    "# Initialize RealSense pipeline\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "\n",
    "# Configure streams - using 640x480 for good balance of speed and quality\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "\n",
    "# Start the pipeline\n",
    "profile = pipeline.start(config)\n",
    "\n",
    "print(\"‚úÖ Camera pipeline started!\")\n",
    "print(f\"   Color Stream: 640x480 @ 30fps\")\n",
    "print(f\"   Depth Stream: 640x480 @ 30fps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd36e38e",
   "metadata": {},
   "source": [
    "## 5. Load YOLOv8 COCO Model\n",
    "\n",
    "Load the YOLOv8 COCO model (e.g., yolov8n.pt) and move it to the appropriate device (CPU/GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "171b4556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ COCO YOLOv8 model loaded!\n",
      "   Model: YOLOv8 Nano (COCO)\n",
      "   Device: CUDA (NVIDIA GeForce RTX 5070 Ti)\n",
      "   Classes: 80 object types\n"
     ]
    }
   ],
   "source": [
    "# Load YOLOv8 COCO model (will download automatically on first run)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "coco_model = YOLO('yolov8n.pt')\n",
    "coco_model.to(device)\n",
    "\n",
    "print(\"‚úÖ COCO YOLOv8 model loaded!\")\n",
    "print(f\"   Model: YOLOv8 Nano (COCO)\")\n",
    "print(f\"   Device: {device.upper()}\" + (f\" ({torch.cuda.get_device_name(0)})\" if device == 'cuda' else \"\"))\n",
    "print(f\"   Classes: {len(coco_model.names)} object types\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe751f55",
   "metadata": {},
   "source": [
    "## 6. Real-Time Detection Loop\n",
    "\n",
    "Run real-time detection using the YOLOv8 COCO model. Press 'q' in the OpenCV window to quit. FPS, class name, and depth are displayed for each detected object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f1dc7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé• Starting real-time detection with COCO model...\n",
      "   Press 'q' in the video window to quit\n",
      "üî¥ Recording video to: videos\\04_detection.avi\n",
      "\n",
      "‚è±Ô∏è Stopped after 60 seconds\n",
      "‚úÖ Video saved to: videos\\04_detection.avi\n",
      "‚úÖ Detection stopped. Processed 1800 frames, avg FPS: 30.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def run_coco_realtime_detection(model, duration_seconds=60, record_video=True, video_path=None):\n",
    "    \"\"\"\n",
    "    Run real-time detection using the COCO-pretrained YOLO model.\n",
    "    Press 'q' to quit early. Optionally records the detection video.\n",
    "    \"\"\"\n",
    "    print(\"üé• Starting real-time detection with COCO model...\")\n",
    "    print(\"   Press 'q' in the video window to quit\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "    fps = 0\n",
    "    video_writer = None\n",
    "    if record_video:\n",
    "        # Create 'videos' directory if it doesn't exist\n",
    "        videos_dir = \"videos\"\n",
    "        os.makedirs(videos_dir, exist_ok=True)\n",
    "        # Find next available filename (01..., 02..., etc.)\n",
    "        existing = [f for f in os.listdir(videos_dir) if f.endswith('.avi') and f[:2].isdigit()]\n",
    "        nums = [int(f[:2]) for f in existing if f[:2].isdigit()]\n",
    "        next_num = max(nums) + 1 if nums else 1\n",
    "        filename = f\"{next_num:02d}_detection.avi\"\n",
    "        video_path = os.path.join(videos_dir, filename)\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        video_writer = cv2.VideoWriter(video_path, fourcc, 30, (640, 480))\n",
    "        print(f\"üî¥ Recording video to: {video_path}\")\n",
    "    try:\n",
    "        while True:\n",
    "            elapsed = time.time() - start_time\n",
    "            if elapsed > duration_seconds:\n",
    "                print(f\"\\n‚è±Ô∏è Stopped after {duration_seconds} seconds\")\n",
    "                break\n",
    "            frames = pipeline.wait_for_frames()\n",
    "            color_frame = frames.get_color_frame()\n",
    "            depth_frame = frames.get_depth_frame()\n",
    "            if not color_frame:\n",
    "                continue\n",
    "            color_image = np.asanyarray(color_frame.get_data())\n",
    "            depth_image = np.asanyarray(depth_frame.get_data())\n",
    "            results = model(color_image, conf=0.3, verbose=False)\n",
    "            annotated_frame = results[0].plot()\n",
    "            frame_count += 1\n",
    "            if frame_count % 10 == 0:\n",
    "                fps = frame_count / elapsed\n",
    "            cv2.putText(annotated_frame, f\"FPS: {fps:.1f}\", (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(annotated_frame, \"COCO YOLOv8 Model\", (10, 60),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "            for r in results:\n",
    "                for box in r.boxes:\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                    cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "                    if 0 <= cx < 640 and 0 <= cy < 480:\n",
    "                        depth_m = depth_image[cy, cx] / 1000.0\n",
    "                        cv2.putText(annotated_frame, f\"{depth_m:.2f}m\", \n",
    "                                    (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                                    0.5, (0, 255, 255), 2)\n",
    "            cv2.imshow(\"COCO YOLOv8 Detection - RealSense D435\", annotated_frame)\n",
    "            if record_video and video_writer is not None:\n",
    "                video_writer.write(annotated_frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                print(\"\\nüëã Quit by user\")\n",
    "                break\n",
    "    finally:\n",
    "        cv2.destroyAllWindows()\n",
    "        if record_video and video_writer is not None:\n",
    "            video_writer.release()\n",
    "            print(f\"‚úÖ Video saved to: {video_path}\")\n",
    "        print(f\"‚úÖ Detection stopped. Processed {frame_count} frames, avg FPS: {fps:.1f}\")\n",
    "\n",
    "# Run for 60 seconds (or press 'q' to quit), recording video with unique filename in 'videos' folder\n",
    "run_coco_realtime_detection(coco_model, duration_seconds=60, record_video=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dd6b1a",
   "metadata": {},
   "source": [
    "## 7. Cleanup\n",
    "\n",
    "Stop the camera pipeline and close all OpenCV windows to release resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c8c4485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Camera pipeline stopped and resources released.\n"
     ]
    }
   ],
   "source": [
    "# Stop the pipeline and release resources\n",
    "if 'pipeline' in globals():\n",
    "    try:\n",
    "        pipeline.stop()\n",
    "    except RuntimeError as e:\n",
    "        print(f\"‚ö†Ô∏è Pipeline stop skipped: {e}\")\n",
    "cv2.destroyAllWindows()\n",
    "print(\"‚úÖ Camera pipeline stopped and resources released.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e36a38",
   "metadata": {},
   "source": [
    "# üì∏ Collect Custom Images for Robotic Arm Dataset\n",
    "\n",
    "Use the following cell to capture and save images of robotic arms with your RealSense camera. These images can be annotated and used to fine-tune your YOLOv8 model for better recognition of robot arms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f59d6347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 's' to save an image, 'q' to quit.\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143434_000.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143436_001.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143455_002.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143456_003.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143508_004.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143509_005.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143543_006.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143544_007.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143548_008.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143552_009.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143554_010.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143556_011.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143558_012.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143600_013.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143602_014.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143606_015.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143608_016.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143611_017.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143621_018.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143622_019.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143624_020.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143625_021.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143648_022.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143648_023.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143650_024.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143701_025.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143706_026.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143711_027.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143722_028.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143729_029.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143730_030.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143731_031.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143733_032.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143733_033.jpg\n",
      "Saved: robot_arm_dataset/images\\robot_arm_20260203_143734_034.jpg\n",
      "Quitting image collection.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Directory to save images\n",
    "save_dir = \"robot_arm_dataset/images\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Start RealSense pipeline\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "profile = pipeline.start(config)\n",
    "\n",
    "print(\"Press 's' to save an image, 'q' to quit.\")\n",
    "count = 0\n",
    "try:\n",
    "    while True:\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        if not color_frame:\n",
    "            continue\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "        cv2.imshow('RealSense - Image Collection', color_image)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('s'):\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            filename = f\"robot_arm_{timestamp}_{count:03d}.jpg\"\n",
    "            filepath = os.path.join(save_dir, filename)\n",
    "            cv2.imwrite(filepath, color_image)\n",
    "            print(f\"Saved: {filepath}\")\n",
    "            count += 1\n",
    "        elif key == ord('q'):\n",
    "            print(\"Quitting image collection.\")\n",
    "            break\n",
    "finally:\n",
    "    pipeline.stop()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26f3edb",
   "metadata": {},
   "source": [
    "## üè∑Ô∏è Annotate Images with LabelImg\n",
    "\n",
    "Follow these steps to annotate your captured images using LabelImg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37814e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install LabelImg (run this cell)\n",
    "%pip install labelImg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b703d6",
   "metadata": {},
   "source": [
    "### How to Annotate with LabelImg\n",
    "\n",
    "1. Run the previous cell to install LabelImg.\n",
    "2. In your terminal, launch LabelImg:\n",
    "   \n",
    "   ```sh\n",
    "   labelImg\n",
    "   ```\n",
    "3. Open your image folder (`robot_arm_dataset/images`).\n",
    "4. Set the save directory to `robot_arm_dataset/labels`.\n",
    "5. In the dropdown, select YOLO format.\n",
    "6. Draw bounding boxes around each robotic arm and label as `robot arm`.\n",
    "7. Save each annotation (a `.txt` file will be created for each image).\n",
    "\n",
    "Once done, you‚Äôll have YOLO-format labels ready for training!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (RealSense)",
   "language": "python",
   "name": "realsense"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
